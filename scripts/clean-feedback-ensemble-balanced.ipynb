{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931e0a1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:49:50.642076Z",
     "iopub.status.busy": "2022-03-12T20:49:50.640575Z",
     "iopub.status.idle": "2022-03-12T20:50:27.210769Z",
     "shell.execute_reply": "2022-03-12T20:50:27.211240Z",
     "shell.execute_reply.started": "2022-03-11T10:39:14.29645Z"
    },
    "papermill": {
     "duration": 36.583985,
     "end_time": "2022-03-12T20:50:27.211595",
     "exception": false,
     "start_time": "2022-03-12T20:49:50.627610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q \"../input/autocorrect/autocorrect-2.6.1.tar\"\n",
    "\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "from torch.utils.data.sampler import *\n",
    "from joblib import Parallel, delayed\n",
    "from autocorrect import Speller\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "spell_correct = Speller(lang='en', fast=True)\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "import tez\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f06fbb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:50:27.241823Z",
     "iopub.status.busy": "2022-03-12T20:50:27.240998Z",
     "iopub.status.idle": "2022-03-12T20:50:27.242971Z",
     "shell.execute_reply": "2022-03-12T20:50:27.243331Z",
     "shell.execute_reply.started": "2022-03-11T10:39:51.466529Z"
    },
    "papermill": {
     "duration": 0.022659,
     "end_time": "2022-03-12T20:50:27.243502",
     "exception": false,
     "start_time": "2022-03-12T20:50:27.220843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ARGS\n",
    "target_id_map = {\n",
    "    \"B-Lead\": 0,\n",
    "    \"I-Lead\": 1,\n",
    "    \"B-Position\": 2,\n",
    "    \"I-Position\": 3,\n",
    "    \"B-Evidence\": 4,\n",
    "    \"I-Evidence\": 5,\n",
    "    \"B-Claim\": 6,\n",
    "    \"I-Claim\": 7,\n",
    "    \"B-Concluding Statement\": 8,\n",
    "    \"I-Concluding Statement\": 9,\n",
    "    \"B-Counterclaim\": 10,\n",
    "    \"I-Counterclaim\": 11,\n",
    "    \"B-Rebuttal\": 12,\n",
    "    \"I-Rebuttal\": 13,\n",
    "    \"O\": 14,\n",
    "    \"PAD\": -100,\n",
    "}\n",
    "\n",
    "\n",
    "id_target_map = {v: k for k, v in target_id_map.items()}\n",
    "class args1: #longformer\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/longformerlarge4096/longformer-large-4096\"\n",
    "    tez_model= \"../input/spellchecker-fold0\"\n",
    "    output = \".\"\n",
    "    batch_size = 4\n",
    "    max_len = 1600\n",
    "    \n",
    "class args2: #longformer trivia\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/triviabase/longformer-large-4096-finetuned-triviaqa\"\n",
    "    tez_model= \"../input/trivia4096\"\n",
    "    output = \".\"\n",
    "    batch_size = 4\n",
    "    max_len = 1600\n",
    "\n",
    "class args3: #deberta\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/deberta-xlarge/\"\n",
    "    tez_model= \"../input/at-model-deberta-xlarge/data_deberta\"\n",
    "    output = \".\"\n",
    "    batch_size = 4\n",
    "    max_len = 1600\n",
    "    \n",
    "class args4: #bigbird\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/bigbirdrobertalarge/bigbird-roberta-large/\"\n",
    "    tez_model= \"../input/at-model-sufferin-bird/bigbird\"\n",
    "    output = \".\"\n",
    "    batch_size = 2\n",
    "    max_len = 1536\n",
    "    \n",
    "class args5: #funnel\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/funnelbasefiles/large\"\n",
    "    tez_model= \"../input/funnellarge\"\n",
    "    output = \".\"\n",
    "    batch_size = 2\n",
    "    max_len = 1536\n",
    "\n",
    "# class args6: #crawl model\n",
    "#     input_path = \"../input/feedback-prize-2021/\"\n",
    "#     model = \"../input/longformerlarge4096/longformer-large-4096/\"\n",
    "#     tez_model= \"../input/at-model-diff\"\n",
    "#     output = \".\"\n",
    "#     batch_size = 4\n",
    "#     max_len = 1536\n",
    "    \n",
    "# class args7: #at model different data\n",
    "#     input_path = \"../input/feedback-prize-2021/\"\n",
    "#     model = \"../input/triviaqa/longformer-large-4096-finetuned-triviaqa\"\n",
    "#     tez_model= \"../input/at-model-trivia-2/different_data/\"\n",
    "#     output = \".\"\n",
    "#     batch_size = 4\n",
    "#     max_len = 1536\n",
    "    \n",
    "class args8: #deberta base\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/debertabasehf/deberta-base\"\n",
    "    tez_model= \"../input/debertaallfolds\"\n",
    "    output = \".\"\n",
    "    batch_size = 4\n",
    "    max_len = 1600\n",
    "    \n",
    "class args9: #deberta large\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/debertalargesample/deberta-large\"\n",
    "    tez_model= \"../input/debertalarge\"\n",
    "    output = \".\"\n",
    "    batch_size = 4\n",
    "    max_len = 1600\n",
    "    \n",
    "class args10: #deberta large\n",
    "    input_path = \"../input/feedback-prize-2021/\"\n",
    "    model = \"../input/debertalargesample/deberta-large\"\n",
    "    tez_model= \"../input/debertasmoothlarge\"\n",
    "    output = \".\"\n",
    "    batch_size = 4\n",
    "    max_len = 1600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0edadd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:50:27.277589Z",
     "iopub.status.busy": "2022-03-12T20:50:27.276758Z",
     "iopub.status.idle": "2022-03-12T20:50:27.278663Z",
     "shell.execute_reply": "2022-03-12T20:50:27.279038Z",
     "shell.execute_reply.started": "2022-03-11T10:39:51.48675Z"
    },
    "papermill": {
     "duration": 0.027318,
     "end_time": "2022-03-12T20:50:27.279154",
     "exception": false,
     "start_time": "2022-03-12T20:50:27.251836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GEN UTILS\n",
    "class FeedbackDataset:\n",
    "    def __init__(self, samples, max_len, tokenizer):\n",
    "        self.samples = samples\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.length = len(samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.samples[idx][\"input_ids\"]\n",
    "        input_ids = [self.tokenizer.cls_token_id] + input_ids\n",
    "        if len(input_ids) > self.max_len - 1:\n",
    "            input_ids = input_ids[: self.max_len - 1]\n",
    "        input_ids = input_ids + [self.tokenizer.sep_token_id]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        return {\n",
    "            \"ids\": input_ids,\n",
    "            \"mask\": attention_mask,\n",
    "        }\n",
    "    \n",
    "class Collate:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        output = dict()\n",
    "        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n",
    "        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n",
    "        batch_max = max([len(ids) for ids in output[\"ids\"]])\n",
    "        if self.tokenizer.padding_side == \"right\":\n",
    "            output[\"ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"ids\"]]\n",
    "            output[\"mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"mask\"]]\n",
    "        else:\n",
    "            output[\"ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"ids\"]]\n",
    "            output[\"mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"mask\"]]\n",
    "        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n",
    "        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n",
    "        return output\n",
    "    \n",
    "def _prepare_test_data_helper(args, tokenizer, ids, spell_check):\n",
    "    test_samples = []\n",
    "    for idx in ids:\n",
    "        filename = os.path.join(args.input_path, \"test\", idx + \".txt\")\n",
    "        with open(filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "        if spell_check:\n",
    "            text = spell_correct(text)\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "        )\n",
    "        input_ids = encoded_text[\"input_ids\"]\n",
    "        offset_mapping = encoded_text[\"offset_mapping\"]\n",
    "\n",
    "        sample = {\n",
    "            \"id\": idx,\n",
    "            \"input_ids\": input_ids,\n",
    "            \"text\": text,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "        }\n",
    "        test_samples.append(sample)\n",
    "    return test_samples\n",
    "\n",
    "def prepare_test_data(df, tokenizer, args, spell_check = False):\n",
    "    test_samples = []\n",
    "    ids = df[\"id\"].unique()\n",
    "    ids_splits = np.array_split(ids, 4)\n",
    "    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n",
    "        delayed(_prepare_test_data_helper)(args, tokenizer, idx, spell_check) for idx in ids_splits\n",
    "    )\n",
    "    for result in results:\n",
    "        test_samples.extend(result)\n",
    "    return test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7b44ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:50:27.314610Z",
     "iopub.status.busy": "2022-03-12T20:50:27.313404Z",
     "iopub.status.idle": "2022-03-12T20:50:27.316410Z",
     "shell.execute_reply": "2022-03-12T20:50:27.316818Z",
     "shell.execute_reply.started": "2022-03-11T10:39:51.507693Z"
    },
    "papermill": {
     "duration": 0.029479,
     "end_time": "2022-03-12T20:50:27.316936",
     "exception": false,
     "start_time": "2022-03-12T20:50:27.287457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODELS\n",
    "class FeedbackModelLongformer(tez.Model):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_dropout_prob: float = 0.1\n",
    "        layer_norm_eps: float = 1e-7\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        self.transformer = AutoModel.from_config(config)\n",
    "        self.output = nn.Linear(config.hidden_size, self.num_labels)\n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out.last_hidden_state\n",
    "        logits = self.output(sequence_output)\n",
    "        logits = torch.softmax(logits, dim=-1)\n",
    "        return logits, 0, {}\n",
    "    \n",
    "class FeedbackModelDeberta(tez.Model):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_dropout_prob: float = 0.1\n",
    "        layer_norm_eps: float = 1e-7\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False\n",
    "            }\n",
    "        )\n",
    "        self.transformer = AutoModel.from_config(config)\n",
    "        self.output = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out.last_hidden_state\n",
    "        logits = self.output(sequence_output)\n",
    "        logits = torch.softmax(logits, dim=-1)\n",
    "        return logits, 0, {}\n",
    "\n",
    "class FeedbackModelBigbird(tez.Model):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_dropout_prob: float = 0.1\n",
    "        layer_norm_eps: float = 1e-7\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "                \"attention_type\" : \"original_full\"\n",
    "            }\n",
    "        )\n",
    "        self.transformer = AutoModel.from_config(config)\n",
    "        self.output = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out.last_hidden_state\n",
    "        logits = self.output(sequence_output)\n",
    "        logits = torch.softmax(logits, dim=-1)\n",
    "        return logits, 0, {}\n",
    "    \n",
    "class FeedbackModelFunnel(tez.Model):\n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.num_labels = num_labels\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        hidden_dropout_prob: float = 0.1\n",
    "        layer_norm_eps: float = 1e-7\n",
    "        config.update(\n",
    "            {\n",
    "                \"output_hidden_states\": True,\n",
    "                \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "                \"layer_norm_eps\": layer_norm_eps,\n",
    "                \"add_pooling_layer\": False,\n",
    "            }\n",
    "        )\n",
    "        self.transformer = AutoModel.from_config(config)\n",
    "        self.output = nn.Linear(config.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        transformer_out = self.transformer(ids, mask)\n",
    "        sequence_output = transformer_out.last_hidden_state\n",
    "        logits = self.output(sequence_output)\n",
    "        logits = torch.softmax(logits, dim=-1)\n",
    "        return logits, 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc299082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:50:27.365515Z",
     "iopub.status.busy": "2022-03-12T20:50:27.364868Z",
     "iopub.status.idle": "2022-03-12T20:56:59.853314Z",
     "shell.execute_reply": "2022-03-12T20:56:59.853776Z",
     "shell.execute_reply.started": "2022-03-11T10:39:51.531998Z"
    },
    "papermill": {
     "duration": 392.528144,
     "end_time": "2022-03-12T20:56:59.853957",
     "exception": false,
     "start_time": "2022-03-12T20:50:27.325813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (742 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (799 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total folds:  14\n",
      "Predicting Model: 1\tFold: 0\tWeight: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.24s/it, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 1\tFold: 3\tWeight: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.40it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 2\tFold: 1\tWeight: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.39it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 2\tFold: 3\tWeight: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.40it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 3\tFold: 1\tWeight: 0.09999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.76s/it, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 3\tFold: 3\tWeight: 0.09999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.70s/it, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 3\tFold: 4\tWeight: 0.09999999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.72s/it, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 9\tFold: 0\tWeight: 0.06666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.09it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 9\tFold: 2\tWeight: 0.06666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.05it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 9\tFold: 4\tWeight: 0.06666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.09it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 10\tFold: 0\tWeight: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.08it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 10\tFold: 1\tWeight: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.10it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 10\tFold: 3\tWeight: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.08it/s, stage=test]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Model: 10\tFold: 4\tWeight: 0.075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.10it/s, stage=test]\n"
     ]
    }
   ],
   "source": [
    "# BLEND\n",
    "df = pd.read_csv(os.path.join(\"../input/feedback-prize-2021/\", \"sample_submission.csv\"))\n",
    "# df = pd.read_csv(\"../input/creating-folds-properly-hopefully-p/train_folds.csv\")\n",
    "df_ids = df[\"id\"].unique()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args1.model)\n",
    "test_samples = prepare_test_data(df, tokenizer, args1, spell_check = True)\n",
    "collate = Collate(tokenizer=tokenizer)\n",
    "test_dataset = FeedbackDataset(test_samples, args1.max_len, tokenizer)\n",
    "# test_dataset = FeedbackDataset(df_text, tokenizer, max_length)\n",
    "\n",
    "\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(args3.model)\n",
    "test_samples3 = prepare_test_data(df, tokenizer3, args3, spell_check = True)\n",
    "collate3 = Collate(tokenizer=tokenizer3)\n",
    "test_dataset3 = FeedbackDataset(test_samples3, args3.max_len, tokenizer3)\n",
    "\n",
    "# tokenizer4 = AutoTokenizer.from_pretrained(args4.model)\n",
    "# test_samples4 = prepare_test_data(df, tokenizer4, args4, spell_check = True)\n",
    "# collate4 = Collate(tokenizer=tokenizer4)\n",
    "# test_dataset4 = FeedbackDataset(test_samples4, args4.max_len, tokenizer4)\n",
    "# test_dataset4 = FeedbackDataset(df_text, tokenizer, max_length)\n",
    "\n",
    "# tokenizer5 = AutoTokenizer.from_pretrained(args5.model)\n",
    "# test_samples5 = prepare_test_data(df, tokenizer5, args5, spell_check = True)\n",
    "# collate5 = Collate(tokenizer=tokenizer5)\n",
    "# test_dataset5 = FeedbackDataset(test_samples5, args5.max_len, tokenizer5)\n",
    "\n",
    "tokenizer8 = AutoTokenizer.from_pretrained(args8.model)\n",
    "test_samples8 = prepare_test_data(df, tokenizer8, args8)\n",
    "collate8 = Collate(tokenizer=tokenizer8)\n",
    "test_dataset8 = FeedbackDataset(test_samples8, args8.max_len, tokenizer8)\n",
    "\n",
    "tokenizer9 = AutoTokenizer.from_pretrained(args9.model)\n",
    "test_samples9 = prepare_test_data(df, tokenizer9, args9)\n",
    "collate9 = Collate(tokenizer=tokenizer9)\n",
    "test_dataset9 = FeedbackDataset(test_samples9, args9.max_len, tokenizer9)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "models = {\n",
    "    1: { #longformer\n",
    "        \"folds_used\":[0,3],\n",
    "        \"weight\": .10             # ensure that these weights sum to 1.0\n",
    "    },\n",
    "    2:{ #longformer trivia\n",
    "        \"folds_used\":[1,3],\n",
    "        \"weight\": .10\n",
    "    },\n",
    "    3:{ #deberta\n",
    "        \"folds_used\":[1,3,4],\n",
    "        \"weight\": .30\n",
    "    },\n",
    "#     4:{ #bigbird\n",
    "#         \"folds_used\":[0],\n",
    "#         \"weight\":1/4\n",
    "#     },\n",
    "#     5:{ #funnel\n",
    "#         \"folds_used\":[0],\n",
    "#         \"weight\":1/4\n",
    "#     }\n",
    "#     6:{ #crawl model\n",
    "#         \"folds_used\":[2]\n",
    "#     },\n",
    "#     7:{ #at model diff data\n",
    "#         \"folds_used\":[2]\n",
    "#     }\n",
    "#     8:{ #deberta base\n",
    "#         \"folds_used\":[1,3],\n",
    "#         \"weight\":.05\n",
    "#     },\n",
    "    9:{\"folds_used\":[0,2,4],\n",
    "      \"weight\":0.20},\n",
    "#     smooth\n",
    "    10:{\"folds_used\":[0,1,3,4],\n",
    "      \"weight\":0.30}\n",
    "    \n",
    "}\n",
    "\n",
    "raw_preds = []\n",
    "checksum = 0\n",
    "total_folds = 0 \n",
    "for model in models.keys():\n",
    "    total_folds += len(models[model][\"folds_used\"])\n",
    "print(\"Total folds: \", total_folds)\n",
    "results = []\n",
    "for i, model_ in enumerate(models.keys()):\n",
    "    folds_used = models[model_][\"folds_used\"]\n",
    "    for j, fold_ in enumerate(folds_used):\n",
    "        current_idx = 0\n",
    "        if model_ == 1:\n",
    "            model = FeedbackModelLongformer(model_name=args1.model, num_labels=len(target_id_map) - 1)\n",
    "            if (fold_) == 0:\n",
    "                model.load('../input/spellchecker-fold0/model_0 (1).bin', weights_only=True)\n",
    "            elif (fold_) == 3:\n",
    "                model.load('../input/spellchecker-fold0/drive-download-20220131T060741Z-002/model_3.bin', weights_only=True)\n",
    "            else:\n",
    "                model.load(os.path.join(args1.tez_model, f\"model_{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset, batch_size=args1.batch_size, n_jobs=-1, collate_fn=collate)\n",
    "                \n",
    "        if model_ == 2:\n",
    "            model = FeedbackModelLongformer(model_name=args2.model, num_labels=len(target_id_map) - 1)\n",
    "            if fold_ == 0:\n",
    "                model.load(os.path.join(args2.tez_model, f\"model_{fold_} (2).bin\"), weights_only=True)\n",
    "            else:\n",
    "                model.load(os.path.join(args2.tez_model, f\"model_{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset, batch_size=args1.batch_size, n_jobs=-1, collate_fn=collate)\n",
    "                \n",
    "        if model_ == 3:\n",
    "            model = FeedbackModelDeberta(model_name=args3.model, num_labels=len(target_id_map) - 1)\n",
    "            model.load(os.path.join(args3.tez_model, f\"model_1024_debberta_{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset3, batch_size=args3.batch_size, n_jobs=-1, collate_fn=collate3)\n",
    "            \n",
    "        if model_ == 4:\n",
    "            model = FeedbackModelBigbird(model_name=args4.model, num_labels=len(target_id_map) - 1)\n",
    "            model.load(os.path.join(args4.tez_model, f\"model_1024_bigbird_10_{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset4, batch_size=args4.batch_size, n_jobs=-1, collate_fn=collate4)\n",
    "\n",
    "        if model_ == 5:\n",
    "            model = FeedbackModelFunnel(model_name=args5.model, num_labels=len(target_id_map) - 1)\n",
    "            model.load(os.path.join(args5.tez_model, f\"funnel{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset5, batch_size=args5.batch_size, n_jobs=-1, collate_fn=collate5)\n",
    "        \n",
    "        if model_ == 6:\n",
    "            model = FeedbackModelLongformer(model_name=args6.model, num_labels=len(target_id_map) - 1)\n",
    "            model.load(os.path.join(args6.tez_model, f\"crawl-model_1048_10_{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset, batch_size=args6.batch_size, n_jobs=-1, collate_fn=collate)\n",
    "        \n",
    "        if model_ == 7:\n",
    "            model = FeedbackModelLongformer(model_name=args7.model, num_labels=len(target_id_map) - 1)\n",
    "            model.load(os.path.join(args7.tez_model, f\"model_1400_trivia_{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset, batch_size=args7.batch_size, n_jobs=-1, collate_fn=collate)\n",
    "        \n",
    "        if model_ == 8:\n",
    "            model = FeedbackModelDeberta(model_name=args8.model, num_labels=len(target_id_map) - 1)\n",
    "            model.load(os.path.join(args8.tez_model, f\"deberta{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset3, batch_size=args8.batch_size, n_jobs=-1, collate_fn=collate8)\n",
    "        \n",
    "        if model_ == 9:\n",
    "            model = FeedbackModelDeberta(model_name=args9.model, num_labels=len(target_id_map) - 1)\n",
    "            model.load(os.path.join(args9.tez_model, f\"debertaLarge{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset3, batch_size=args9.batch_size, n_jobs=-1, collate_fn=collate9)\n",
    "            \n",
    "        if model_ == 10:\n",
    "            model = FeedbackModelDeberta(model_name=args10.model, num_labels=len(target_id_map) - 1)\n",
    "            model.load(os.path.join(args10.tez_model, f\"debertaSmoothlLarge{fold_}.bin\"), weights_only=True)\n",
    "            preds_iter = model.predict(test_dataset3, batch_size=args9.batch_size, n_jobs=-1, collate_fn=collate9)\n",
    "            \n",
    "        print(f\"Predicting Model: {model_}\\tFold: {fold_}\\tWeight: {(1/len(folds_used)) * models[model_]['weight']}\")\n",
    "        checksum += (1/len(folds_used)) * models[model_]['weight']\n",
    "        current_idx = 0\n",
    "        for preds in preds_iter:\n",
    "            preds = preds.astype(np.float32)\n",
    "#             preds = preds / total_folds\n",
    "            preds = preds * (1/len(folds_used)) * models[model_]['weight']\n",
    "            if i==0 and j==0:\n",
    "                raw_preds.append(preds)\n",
    "            else:\n",
    "#                 if preds.shape[1]>np.array(raw_preds,dtype=object).shape[2]:\n",
    "#                     preds = preds[:,:np.array(raw_preds,dtype=object).shape[2],:]\n",
    "                raw_preds[current_idx] += preds\n",
    "                current_idx += 1\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c24d87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:56:59.936785Z",
     "iopub.status.busy": "2022-03-12T20:56:59.935140Z",
     "iopub.status.idle": "2022-03-12T20:56:59.938676Z",
     "shell.execute_reply": "2022-03-12T20:56:59.938199Z",
     "shell.execute_reply.started": "2022-03-11T10:44:32.411639Z"
    },
    "papermill": {
     "duration": 0.047026,
     "end_time": "2022-03-12T20:56:59.938790",
     "exception": false,
     "start_time": "2022-03-12T20:56:59.891764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998\n",
      "1.0000001\n"
     ]
    }
   ],
   "source": [
    "print(checksum)\n",
    "# print(np.array(preds).shape)\n",
    "print(np.array(raw_preds,dtype=object)[0][0][0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3555e42f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:57:00.021413Z",
     "iopub.status.busy": "2022-03-12T20:57:00.016235Z",
     "iopub.status.idle": "2022-03-12T20:57:00.025321Z",
     "shell.execute_reply": "2022-03-12T20:57:00.025720Z",
     "shell.execute_reply.started": "2022-03-11T10:44:32.413685Z"
    },
    "papermill": {
     "duration": 0.049518,
     "end_time": "2022-03-12T20:57:00.025855",
     "exception": false,
     "start_time": "2022-03-12T20:56:59.976337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "final_scores = []\n",
    "\n",
    "for rp in raw_preds:\n",
    "    pred_class = np.argmax(rp, axis=2)\n",
    "    pred_scrs = np.max(rp, axis=2)\n",
    "    for pred, pred_scr in zip(pred_class, pred_scrs):\n",
    "        pred = pred.tolist()\n",
    "        pred_scr = pred_scr.tolist()\n",
    "        final_preds.append(pred)\n",
    "        final_scores.append(pred_scr)\n",
    "\n",
    "for j in range(len(test_samples)):\n",
    "    tt = [id_target_map[p] for p in final_preds[j][1:]]\n",
    "    tt_score = final_scores[j][1:]\n",
    "    test_samples[j][\"preds\"] = tt\n",
    "    test_samples[j][\"pred_scores\"] = tt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f745155f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:57:00.147125Z",
     "iopub.status.busy": "2022-03-12T20:57:00.141144Z",
     "iopub.status.idle": "2022-03-12T20:57:00.245479Z",
     "shell.execute_reply": "2022-03-12T20:57:00.245944Z",
     "shell.execute_reply.started": "2022-03-11T10:44:32.415734Z"
    },
    "papermill": {
     "duration": 0.182628,
     "end_time": "2022-03-12T20:57:00.246093",
     "exception": false,
     "start_time": "2022-03-12T20:57:00.063465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    }
   ],
   "source": [
    "# SUBMISSION\n",
    "def link_(oof, claxx = 'Evidence'):\n",
    "  if not len(oof):\n",
    "    return oof\n",
    "  \n",
    "  def jn(pst, start, end):\n",
    "    return \" \".join([str(x) for x in pst[start:end]])\n",
    "  \n",
    "  thresh = 1\n",
    "  idu = oof['id'].unique()\n",
    "  eoof = oof[oof['class'] == claxx]\n",
    "  neoof = oof[oof['class'] != claxx]\n",
    "  eoof.index = eoof[['id', 'class']]\n",
    "  for thresh2 in range(26, 27, 1):\n",
    "    retval = []\n",
    "    for idv in tqdm(idu, desc='link_evidence', leave=False):\n",
    "      for c in [claxx]:\n",
    "        q = eoof[(eoof['id'] == idv)]\n",
    "        if len(q) == 0:\n",
    "          continue\n",
    "        pst = []\n",
    "        for r in q.itertuples():\n",
    "          pst = [*pst, -1,  *[int(x) for x in r.predictionstring.split()]]\n",
    "        start = 1\n",
    "        end = 1\n",
    "        for i in range(2, len(pst)):\n",
    "          cur = pst[i]\n",
    "          end = i\n",
    "          if  ((cur == -1) and ((pst[i + 1] > pst[end - 1] + thresh) or (pst[i + 1] - pst[start] > thresh2))):\n",
    "            retval.append((idv, c, jn(pst, start, end)))\n",
    "            start = i + 1\n",
    "        v = (idv, c, jn(pst, start, end + 1))\n",
    "        retval.append(v)\n",
    "    roof = pd.DataFrame(retval, columns=['id', 'class', 'predictionstring'])\n",
    "    roof = roof.merge(neoof, how='outer')\n",
    "    return roof\n",
    "\n",
    "# proba_thresh = {\n",
    "#     \"Lead\": 0.65,\n",
    "#     \"Position\": 0.55,\n",
    "#     \"Evidence\": 0.6,\n",
    "#     \"Claim\": 0.55,\n",
    "#     \"Concluding Statement\": 0.7,\n",
    "#     \"Counterclaim\": 0.5,\n",
    "#     \"Rebuttal\": 0.55,\n",
    "# }\n",
    "proba_thresh = { #higher\n",
    "    \"Lead\": 0.687,\n",
    "    \"Position\": 0.537,\n",
    "    \"Evidence\": 0.637,\n",
    "    \"Claim\": 0.537,\n",
    "    \"Concluding Statement\": 0.687,\n",
    "    \"Counterclaim\": 0.537,\n",
    "    \"Rebuttal\": 0.537,\n",
    "}\n",
    "\n",
    "min_thresh = {\n",
    "    \"Lead\": 9,\n",
    "    \"Position\": 5,\n",
    "    \"Evidence\": 14,\n",
    "    \"Claim\": 3,\n",
    "    \"Concluding Statement\": 11,\n",
    "    \"Counterclaim\": 6,\n",
    "    \"Rebuttal\": 4,\n",
    "}\n",
    "\n",
    "submission = []\n",
    "for sample_idx, sample in enumerate(test_samples):\n",
    "    preds = sample[\"preds\"]\n",
    "    offset_mapping = sample[\"offset_mapping\"]\n",
    "    sample_id = sample[\"id\"]\n",
    "    sample_text = sample[\"text\"]\n",
    "    sample_input_ids = sample[\"input_ids\"]\n",
    "    sample_pred_scores = sample[\"pred_scores\"]\n",
    "    sample_preds = []\n",
    "\n",
    "    if len(preds) < len(offset_mapping):\n",
    "        preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n",
    "        sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n",
    "    \n",
    "    idx = 0\n",
    "    phrase_preds = []\n",
    "    while idx < len(offset_mapping):\n",
    "        start, _ = offset_mapping[idx]\n",
    "        if preds[idx] != \"O\":\n",
    "            label = preds[idx][2:]\n",
    "        else:\n",
    "            label = \"O\"\n",
    "        phrase_scores = []\n",
    "        phrase_scores.append(sample_pred_scores[idx])\n",
    "        idx += 1\n",
    "        while idx < len(offset_mapping):\n",
    "            if label == \"O\":\n",
    "                matching_label = \"O\"\n",
    "            else:\n",
    "                matching_label = f\"I-{label}\"\n",
    "            if preds[idx] == matching_label:\n",
    "                _, end = offset_mapping[idx]\n",
    "                phrase_scores.append(sample_pred_scores[idx])\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "        if \"end\" in locals():\n",
    "            phrase = sample_text[start:end]\n",
    "            phrase_preds.append((phrase, start, end, label, phrase_scores))\n",
    "\n",
    "    temp_df = []\n",
    "    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n",
    "        word_start = len(sample_text[:start].split())\n",
    "        word_end = word_start + len(sample_text[start:end].split())\n",
    "        word_end = min(word_end, len(sample_text.split()))\n",
    "        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n",
    "        if label != \"O\":\n",
    "            if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n",
    "                if len(ps.split()) >= min_thresh[label]:\n",
    "                    temp_df.append((sample_id, label, ps))\n",
    "    \n",
    "    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n",
    "    submission.append(temp_df)\n",
    "\n",
    "submission = pd.concat(submission).reset_index(drop=True)\n",
    "submission = link_(submission, 'Evidence')\n",
    "submission = link_(submission, 'Lead')\n",
    "submission = link_(submission, 'Position')\n",
    "# submission = link_(submission, 'Claim')\n",
    "submission = link_(submission, 'Concluding Statement')\n",
    "submission = link_(submission, 'Counterclaim')\n",
    "submission = link_(submission, 'Rebuttal')\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63c781a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-12T20:57:00.340212Z",
     "iopub.status.busy": "2022-03-12T20:57:00.339281Z",
     "iopub.status.idle": "2022-03-12T20:57:00.350830Z",
     "shell.execute_reply": "2022-03-12T20:57:00.351297Z",
     "shell.execute_reply.started": "2022-03-11T10:44:32.417797Z"
    },
    "papermill": {
     "duration": 0.063253,
     "end_time": "2022-03-12T20:57:00.351487",
     "exception": false,
     "start_time": "2022-03-12T20:57:00.288234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18409261F5C2</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>989 990 991 992 993 994 995 996 997 998 999 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D46BCB48440A</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>306 307 308 309 310 311 312 313 314 315 316 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0FB0700DAF44</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>560 561 562 563 564 565 566 567 568 569 570 57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>364 365 366 367 368 369 370 371 372 373 374 37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DF920E0A7337</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>620 621 622 623 624 625 626 627 628 629 630 63...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                 class  \\\n",
       "0  18409261F5C2  Concluding Statement   \n",
       "1  D46BCB48440A  Concluding Statement   \n",
       "2  0FB0700DAF44  Concluding Statement   \n",
       "3  D72CB1C11673  Concluding Statement   \n",
       "4  DF920E0A7337  Concluding Statement   \n",
       "\n",
       "                                    predictionstring  \n",
       "0  989 990 991 992 993 994 995 996 997 998 999 10...  \n",
       "1  306 307 308 309 310 311 312 313 314 315 316 31...  \n",
       "2  560 561 562 563 564 565 566 567 568 569 570 57...  \n",
       "3  364 365 366 367 368 369 370 371 372 373 374 37...  \n",
       "4  620 621 622 623 624 625 626 627 628 629 630 63...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 441.470699,
   "end_time": "2022-03-12T20:57:03.481602",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-12T20:49:42.010903",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
